#
# DATABRICKS CONFIDENTIAL & PROPRIETARY
# __________________
#
# Copyright 2023-present Databricks, Inc.
# All Rights Reserved.
#
# NOTICE:  All information contained herein is, and remains the property of Databricks, Inc.
# and its suppliers, if any.  The intellectual and technical concepts contained herein are
# proprietary to Databricks, Inc. and its suppliers and may be covered by U.S. and foreign Patents,
# patents in process, and are protected by trade secret and/or copyright law. Dissemination, use,
# or reproduction of this information is strictly forbidden unless prior written permission is
# obtained from Databricks, Inc.
#
# If you view or obtain a copy of this information and believe Databricks, Inc. may not have
# intended it to be made available, please promptly report it to Databricks Legal Department
# @ legal@databricks.com.
#
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: spark/connect/cloud.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import builder as _builder
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database

# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
    b'\n\x19spark/connect/cloud.proto\x12\rspark.connect"\xbd\x04\n\rResultOptions\x12\x35\n\x04type\x18\x01 \x01(\x0e\x32!.spark.connect.ResultOptions.TypeR\x04type\x12R\n\x0c\x63loudOptions\x18\x02 \x01(\x0b\x32).spark.connect.ResultOptions.CloudOptionsH\x00R\x0c\x63loudOptions\x88\x01\x01\x1a\xd0\x02\n\x0c\x43loudOptions\x12H\n\x06\x66ormat\x18\x01 \x01(\x0e\x32\x30.spark.connect.ResultOptions.CloudOptions.FormatR\x06\x66ormat\x12+\n\x0euseCompression\x18\x02 \x01(\x08H\x00R\x0euseCompression\x88\x01\x01\x12 \n\trow_limit\x18\x03 \x01(\x03H\x01R\x08rowLimit\x88\x01\x01\x12"\n\nbyte_limit\x18\x04 \x01(\x03H\x02R\tbyteLimit\x88\x01\x01"S\n\x06\x46ormat\x12\x16\n\x12\x46ORMAT_UNSPECIFIED\x10\x00\x12\x10\n\x0c\x46ORMAT_ARROW\x10\x01\x12\x0e\n\nFORMAT_CSV\x10\x02\x12\x0f\n\x0b\x46ORMAT_JSON\x10\x03\x42\x11\n\x0f_useCompressionB\x0c\n\n_row_limitB\r\n\x0b_byte_limit"=\n\x04Type\x12\x14\n\x10TYPE_UNSPECIFIED\x10\x00\x12\x0f\n\x0bTYPE_INLINE\x10\x01\x12\x0e\n\nTYPE_CLOUD\x10\x02\x42\x0f\n\r_cloudOptions"\xac\x02\n\x10\x43loudResultBatch\x12@\n\x07results\x18\x01 \x03(\x0b\x32&.spark.connect.CloudResultBatch.ResultR\x07results\x12\x1c\n\ttruncated\x18\x02 \x01(\x08R\ttruncated\x1a\xb7\x01\n\x06Result\x12\x10\n\x03url\x18\x02 \x01(\tR\x03url\x12\x1b\n\trow_count\x18\x03 \x01(\x03R\x08rowCount\x12\'\n\x0f\x63ompressed_size\x18\x04 \x01(\x03R\x0e\x63ompressedSize\x12+\n\x11uncompressed_size\x18\x05 \x01(\x03R\x10uncompressedSize\x12(\n\x10secret_file_path\x18\x06 \x01(\tR\x0esecretFilePath"9\n\x14SubscribeToLiveQuery\x12!\n\x0coperation_id\x18\x01 \x01(\tR\x0boperationIdB"\n\x1eorg.apache.spark.connect.protoP\x01\x62\x06proto3'
)

_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
_builder.BuildTopDescriptorsAndMessages(
    DESCRIPTOR, "pyspark.sql.connect.proto.cloud_pb2", globals()
)
if _descriptor._USE_C_DESCRIPTORS == False:
    DESCRIPTOR._options = None
    DESCRIPTOR._serialized_options = b"\n\036org.apache.spark.connect.protoP\001"
    _RESULTOPTIONS._serialized_start = 45
    _RESULTOPTIONS._serialized_end = 618
    _RESULTOPTIONS_CLOUDOPTIONS._serialized_start = 202
    _RESULTOPTIONS_CLOUDOPTIONS._serialized_end = 538
    _RESULTOPTIONS_CLOUDOPTIONS_FORMAT._serialized_start = 407
    _RESULTOPTIONS_CLOUDOPTIONS_FORMAT._serialized_end = 490
    _RESULTOPTIONS_TYPE._serialized_start = 540
    _RESULTOPTIONS_TYPE._serialized_end = 601
    _CLOUDRESULTBATCH._serialized_start = 621
    _CLOUDRESULTBATCH._serialized_end = 921
    _CLOUDRESULTBATCH_RESULT._serialized_start = 738
    _CLOUDRESULTBATCH_RESULT._serialized_end = 921
    _SUBSCRIBETOLIVEQUERY._serialized_start = 923
    _SUBSCRIBETOLIVEQUERY._serialized_end = 980
# @@protoc_insertion_point(module_scope)
